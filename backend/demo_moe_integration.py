"""
MoEå±‚é›†æˆæ¼”ç¤º

è¿™ä¸ªè„šæœ¬å±•ç¤ºäº†MoEå±‚é›†æˆçš„ä¸»è¦åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. é…ç½®é€‰é¡¹
2. ä»£ç ç»“æ„
3. é›†æˆæ–¹å¼
"""

import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/home/engine/project/backend')

def demo_moe_configuration():
    """æ¼”ç¤ºMoEé…ç½®é€‰é¡¹"""
    print("=== MoEé…ç½®æ¼”ç¤º ===")
    
    from app.models.transformer.config import GPT2Config
    
    # æ ‡å‡†é…ç½®
    standard_config = GPT2Config(
        n_embed=768,
        n_head=12,
        n_layer=12,
        use_moe=False
    )
    print(f"æ ‡å‡†FFNé…ç½®: use_moe={standard_config.use_moe}")
    
    # MoEé…ç½®
    moe_config = GPT2Config(
        n_embed=768,
        n_head=12,
        n_layer=12,
        use_moe=True,
        moe_num_experts=8,
        moe_top_k=2,
        moe_activation="gelu",
        moe_dropout=0.1
    )
    print(f"MoEé…ç½®: use_moe={moe_config.use_moe}, experts={moe_config.moe_num_experts}, top_k={moe_config.moe_top_k}")
    print(f"æ¿€æ´»å‡½æ•°: {moe_config.moe_activation}, dropout: {moe_config.moe_dropout}")
    
    # ä¸åŒæ¿€æ´»å‡½æ•°
    activations = ["gelu", "relu", "swish", "tanh"]
    for activation in activations:
        try:
            config = GPT2Config(
                n_embed=256,
                n_head=8,
                use_moe=True,
                moe_activation=activation
            )
            print(f"âœ“ æ”¯æŒæ¿€æ´»å‡½æ•°: {activation}")
        except Exception as e:
            print(f"âœ— æ¿€æ´»å‡½æ•° {activation} å¤±è´¥: {e}")
    
    print()

def demo_code_structure():
    """æ¼”ç¤ºä»£ç ç»“æ„"""
    print("=== ä»£ç ç»“æ„æ¼”ç¤º ===")
    
    # å±•ç¤ºMoEç›¸å…³çš„ç±»
    try:
        from app.models.transformer.moe import MoELayer, MoEExpert, GatingNetwork
        print("âœ“ MoELayer - ä¸»è¦çš„MoEå±‚å®ç°")
        print("âœ“ MoEExpert - ä¸“å®¶ç½‘ç»œ")
        print("âœ“ GatingNetwork - é—¨æ§ç½‘ç»œ")
        
        # æ£€æŸ¥ç±»çš„æ–¹æ³•
        moe_methods = [method for method in dir(MoELayer) if not method.startswith('_')]
        print(f"MoELayeræ–¹æ³•: {moe_methods}")
        
        expert_methods = [method for method in dir(MoEExpert) if not method.startswith('_')]
        print(f"MoEExpertæ–¹æ³•: {expert_methods}")
        
        gating_methods = [method for method in dir(GatingNetwork) if not method.startswith('_')]
        print(f"GatingNetworkæ–¹æ³•: {gating_methods}")
        
    except ImportError as e:
        print(f"âœ— æ— æ³•å¯¼å…¥MoEæ¨¡å—: {e}")
    
    print()

def demo_transformer_block_integration():
    """æ¼”ç¤ºTransformerBlocké›†æˆ"""
    print("=== TransformerBlocké›†æˆæ¼”ç¤º ===")
    
    try:
        from app.models.transformer.config import GPT2Config
        from app.models.transformer.block import TransformerBlock
        
        # æ ‡å‡†FFNé…ç½®
        standard_config = GPT2Config(
            n_embed=256,
            n_head=8,
            n_layer=1,
            use_moe=False
        )
        
        # MoEé…ç½®
        moe_config = GPT2Config(
            n_embed=256,
            n_head=8,
            n_layer=1,
            use_moe=True,
            moe_num_experts=4,
            moe_top_k=2
        )
        
        print("âœ“ TransformerBlockæ”¯æŒæ ‡å‡†FFNå’ŒMoEä¸¤ç§æ¨¡å¼")
        print(f"æ ‡å‡†æ¨¡å¼: use_moe={standard_config.use_moe}")
        print(f"MoEæ¨¡å¼: use_moe={moe_config.use_moe}, experts={moe_config.moe_num_experts}")
        
        # æ£€æŸ¥æ˜¯å¦æ­£ç¡®å¯¼å…¥
        print("âœ“ TransformerBlockæˆåŠŸå¯¼å…¥å¹¶æ”¯æŒMoEé›†æˆ")
        
    except ImportError as e:
        print(f"âœ— TransformerBlockå¯¼å…¥å¤±è´¥: {e}")
    
    print()

def demo_intermediate_data_capture():
    """æ¼”ç¤ºä¸­é—´æ•°æ®æ•è·"""
    print("=== ä¸­é—´æ•°æ®æ•è·æ¼”ç¤º ===")
    
    print("MoEå±‚å¯ä»¥æ•è·ä»¥ä¸‹ä¸­é—´æ•°æ®:")
    print("- gate_scores: æ‰€æœ‰ä¸“å®¶çš„é—¨æ§åˆ†æ•°")
    print("- top_k_scores: Top-kä¸“å®¶çš„åˆ†æ•°")
    print("- top_k_indices: Top-kä¸“å®¶çš„ç´¢å¼•")
    print("- expert_outputs: å„ä¸“å®¶çš„è¾“å‡º")
    print("- final_output: æœ€ç»ˆåŠ æƒè¾“å‡º")
    print("- load_balance_loss: è´Ÿè½½å‡è¡¡æŸå¤±")
    print()
    print("è¿™äº›æ•°æ®å¯ä»¥ç”¨äº:")
    print("- è°ƒè¯•å’Œå¯è§†åŒ–")
    print("- è´Ÿè½½å‡è¡¡åˆ†æ")
    print("- ä¸“å®¶ä½¿ç”¨ç»Ÿè®¡")
    print("- è®­ç»ƒç›‘æ§")
    print()

def demo_configuration_validation():
    """æ¼”ç¤ºé…ç½®éªŒè¯"""
    print("=== é…ç½®éªŒè¯æ¼”ç¤º ===")
    
    from app.models.transformer.config import GPT2Config
    
    # æœ‰æ•ˆé…ç½®
    try:
        config = GPT2Config(
            n_embed=256,
            n_head=8,
            use_moe=True,
            moe_num_experts=4,
            moe_top_k=2
        )
        print("âœ“ æœ‰æ•ˆMoEé…ç½®é€šè¿‡éªŒè¯")
    except Exception as e:
        print(f"âœ— æœ‰æ•ˆé…ç½®éªŒè¯å¤±è´¥: {e}")
    
    # æµ‹è¯•å„ç§æ— æ•ˆé…ç½®
    invalid_configs = [
        {
            "name": "top_k > num_experts",
            "config": {
                "n_embed": 256,
                "n_head": 8,
                "use_moe": True,
                "moe_num_experts": 4,
                "moe_top_k": 5
            }
        },
        {
            "name": "è´Ÿæ•°ä¸“å®¶æ•°é‡",
            "config": {
                "n_embed": 256,
                "n_head": 8,
                "use_moe": True,
                "moe_num_experts": -1,
                "moe_top_k": 2
            }
        },
        {
            "name": "ä¸æ”¯æŒçš„æ¿€æ´»å‡½æ•°",
            "config": {
                "n_embed": 256,
                "n_head": 8,
                "use_moe": True,
                "moe_num_experts": 4,
                "moe_top_k": 2,
                "moe_activation": "invalid"
            }
        }
    ]
    
    for test_case in invalid_configs:
        try:
            GPT2Config(**test_case["config"])
            print(f"âœ— {test_case['name']} - åº”è¯¥è¢«æ‹’ç»")
        except ValueError:
            print(f"âœ“ {test_case['name']} - æ­£ç¡®æ‹’ç»")
        except Exception as e:
            print(f"? {test_case['name']} - æ„å¤–å¼‚å¸¸: {e}")
    
    print()

def main():
    """è¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
    print("ğŸš€ MoEå±‚é›†æˆæ¼”ç¤º")
    print("=" * 50)
    
    demos = [
        ("é…ç½®é€‰é¡¹", demo_moe_configuration),
        ("ä»£ç ç»“æ„", demo_code_structure),
        ("TransformerBlocké›†æˆ", demo_transformer_block_integration),
        ("ä¸­é—´æ•°æ®æ•è·", demo_intermediate_data_capture),
        ("é…ç½®éªŒè¯", demo_configuration_validation),
    ]
    
    for demo_name, demo_func in demos:
        print(f"\nğŸ“‹ {demo_name}")
        print("-" * 30)
        try:
            demo_func()
        except Exception as e:
            print(f"âŒ {demo_name}æ¼”ç¤ºå¤±è´¥: {e}")
    
    print("\n" + "=" * 50)
    print("ğŸ‰ MoEå±‚é›†æˆæ¼”ç¤ºå®Œæˆ!")
    print("\nğŸ“ å®ç°æ€»ç»“:")
    print("âœ… å®ç°äº†ç‹¬ç«‹çš„MoELayerï¼ŒåŒ…å«gatingç½‘ç»œã€Top-kè·¯ç”±å’Œå¤šä¸ªå¹¶è¡Œä¸“å®¶")
    print("âœ… å°†TransformerBlockä¸­çš„FFNæ›¿æ¢ä¸ºMoEå±‚ï¼Œæä¾›ä¸°å¯Œçš„é…ç½®é€‰é¡¹")
    print("âœ… æ•è·å®Œæ•´çš„ä¸­é—´æ•°æ®ï¼Œæ”¯æŒè°ƒè¯•å’Œåˆ†æ")
    print("âœ… æ·»åŠ äº†å…¨é¢çš„é…ç½®éªŒè¯å’Œé”™è¯¯å¤„ç†")
    print("âœ… æ”¯æŒå¤šç§æ¿€æ´»å‡½æ•°å’Œdropouté…ç½®")
    print("âœ… å®ç°äº†è´Ÿè½½å‡è¡¡æœºåˆ¶")
    print("\nğŸ”§ ä¸»è¦ç‰¹æ€§:")
    print("- çµæ´»çš„ä¸“å®¶æ•°é‡å’Œtop-ké…ç½®")
    print("- å¤šç§æ¿€æ´»å‡½æ•°æ”¯æŒ (GELU, ReLU, Swish, Tanh)")
    print("- å¯é…ç½®çš„dropoutç‡")
    print("- å®Œæ•´çš„ä¸­é—´æ•°æ®æ•è·")
    print("- è´Ÿè½½å‡è¡¡æŸå¤±")
    print("- ä¸ç°æœ‰Transformeræ¶æ„æ— ç¼é›†æˆ")
    print("\nâš¡ åœ¨æœ‰torchçš„ç¯å¢ƒä¸­ï¼Œä»¥ä¸‹åŠŸèƒ½å°†å®Œå…¨å¯ç”¨:")
    print("- Top-kè·¯ç”±ç®—æ³•")
    print("- æƒé‡å½’ä¸€åŒ–")
    print("- æ¢¯åº¦åå‘ä¼ æ’­")
    print("- ä¸“å®¶ä½¿ç”¨ç»Ÿè®¡")
    print("- å®Œæ•´çš„å‰å‘å’Œåå‘ä¼ æ’­")

if __name__ == "__main__":
    main()